{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows-10-10.0.19045-SP0\n",
      "Python 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import platform; print(platform.platform())\n",
    "import sys; print(\"Python\", sys.version)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os \n",
    "import joblib\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import optuna\n",
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cfg:\n",
    "    modelname = 'catboost'\n",
    "    debug = False\n",
    "    optim = True\n",
    "    seed = 42\n",
    "    nfolds = 5\n",
    "    njobs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "      <th>IsSynthetic</th>\n",
       "      <th>...</th>\n",
       "      <th>Monterey County</th>\n",
       "      <th>Napa County</th>\n",
       "      <th>Orange County</th>\n",
       "      <th>Other</th>\n",
       "      <th>Riverside County</th>\n",
       "      <th>San Francisco County</th>\n",
       "      <th>Santa Barbara County</th>\n",
       "      <th>Santa Clara County</th>\n",
       "      <th>Ventura County</th>\n",
       "      <th>Yolo County</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.3859</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.827160</td>\n",
       "      <td>1.112100</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>2.486989</td>\n",
       "      <td>34.60</td>\n",
       "      <td>-120.12</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.7188</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.013373</td>\n",
       "      <td>1.054217</td>\n",
       "      <td>1504.0</td>\n",
       "      <td>3.813084</td>\n",
       "      <td>38.69</td>\n",
       "      <td>-121.22</td>\n",
       "      <td>0.946</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7750</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.535604</td>\n",
       "      <td>1.103175</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>2.464602</td>\n",
       "      <td>34.71</td>\n",
       "      <td>-120.45</td>\n",
       "      <td>1.576</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.4138</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.350203</td>\n",
       "      <td>0.965432</td>\n",
       "      <td>1255.0</td>\n",
       "      <td>2.089286</td>\n",
       "      <td>32.66</td>\n",
       "      <td>-117.09</td>\n",
       "      <td>1.336</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.7500</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.284404</td>\n",
       "      <td>1.069246</td>\n",
       "      <td>1793.0</td>\n",
       "      <td>1.604790</td>\n",
       "      <td>37.80</td>\n",
       "      <td>-122.41</td>\n",
       "      <td>4.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  2.3859      15.0  3.827160   1.112100      1280.0  2.486989     34.60   \n",
       "1  3.7188      17.0  6.013373   1.054217      1504.0  3.813084     38.69   \n",
       "2  4.7750      27.0  6.535604   1.103175      1061.0  2.464602     34.71   \n",
       "3  2.4138      16.0  3.350203   0.965432      1255.0  2.089286     32.66   \n",
       "4  3.7500      52.0  4.284404   1.069246      1793.0  1.604790     37.80   \n",
       "\n",
       "   Longitude  MedHouseVal  IsSynthetic  ...  Monterey County  Napa County  \\\n",
       "0    -120.12        0.980          1.0  ...              0.0          0.0   \n",
       "1    -121.22        0.946          1.0  ...              0.0          0.0   \n",
       "2    -120.45        1.576          1.0  ...              0.0          0.0   \n",
       "3    -117.09        1.336          1.0  ...              0.0          0.0   \n",
       "4    -122.41        4.500          1.0  ...              0.0          0.0   \n",
       "\n",
       "   Orange County  Other  Riverside County  San Francisco County  \\\n",
       "0            0.0    0.0               0.0                   0.0   \n",
       "1            0.0    1.0               0.0                   0.0   \n",
       "2            0.0    0.0               0.0                   0.0   \n",
       "3            0.0    1.0               0.0                   0.0   \n",
       "4            0.0    0.0               0.0                   1.0   \n",
       "\n",
       "   Santa Barbara County  Santa Clara County  Ventura County  Yolo County  \n",
       "0                   1.0                 0.0             0.0          0.0  \n",
       "1                   0.0                 0.0             0.0          0.0  \n",
       "2                   1.0                 0.0             0.0          0.0  \n",
       "3                   0.0                 0.0             0.0          0.0  \n",
       "4                   0.0                 0.0             0.0          0.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "train = pd.read_csv('../data/final/train.csv')\n",
    "test = pd.read_csv('../data/final/test.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: MedHouseVal\n",
      "Features: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude', 'IsSynthetic', 'AnomalyScore', 'rot_15_x', 'rot_15_y', 'rot_30_x', 'rot_30_y', 'rot_45_x', 'pca_lon', 'pca_lat', 'Alameda County', 'Contra Costa County', 'Fresno County', 'Kern County', 'Los Angeles County', 'Monterey County', 'Napa County', 'Orange County', 'Other', 'Riverside County', 'San Francisco County', 'Santa Barbara County', 'Santa Clara County', 'Ventura County', 'Yolo County']\n",
      "Train set shape: (57777, 33)\n",
      "Test set shape: (24759, 32)\n"
     ]
    }
   ],
   "source": [
    "# quick info\n",
    "TARGET = 'MedHouseVal'\n",
    "FEATURES = [c for c in train.columns if c not in [TARGET]]\n",
    "\n",
    "print(f'Target: {TARGET}\\nFeatures: {FEATURES}')\n",
    "print('Train set shape:', train.shape)\n",
    "print('Test set shape:', test.shape)\n",
    "\n",
    "x = train[FEATURES]\n",
    "y = train[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "params_path = './training_files/params/'\n",
    "os.makedirs(params_path, exist_ok=True)\n",
    "\n",
    "cv = KFold(n_splits=cfg.nfolds, shuffle=True, random_state=cfg.seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed params\n",
    "fixed_params = {\n",
    "    'loss_function': 'RMSE',\n",
    "    'custom_metric': 'RMSE',\n",
    "    'task_type' : 'CPU',\n",
    "    'bootstrap_type': 'Bayesian',\n",
    "    'allow_writing_files': False,\n",
    "}\n",
    "\n",
    "# objective function for optimization\n",
    "def objective(trial):\n",
    "    \n",
    "    # trial parameters\n",
    "    tuning_params = {\n",
    "        'num_trees': trial.suggest_int('num_trees', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 1, 25),\n",
    "        'random_strength': trial.suggest_float('random_strength', 1, 10),\n",
    "        'depth': trial.suggest_int('depth', 1, 8, step=1),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.1, 0.8),\n",
    "        'l2_leaf_reg':trial.suggest_float('l2_leaf_reg', 0, 10)\n",
    "    }\n",
    "\n",
    "    params = {**fixed_params, **tuning_params}\n",
    "\n",
    "    # train and score with cv\n",
    "    scores = []\n",
    "    for train_idx, test_idx in cv.split(x, y):\n",
    "        \n",
    "        # split data\n",
    "        x_train, x_val = x.iloc[train_idx], x.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        # fit model\n",
    "        model = catboost.CatBoostRegressor(**params)\n",
    "        model.fit(\n",
    "            catboost.Pool(x_train, y_train),\n",
    "            eval_set=catboost.Pool(x_val, y_val),\n",
    "            early_stopping_rounds=20,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # obtain score\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, model.predict(x_val)))\n",
    "        scores.append(rmse)\n",
    "\n",
    "    # return mean cv score \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-08 12:51:45,335]\u001b[0m A new study created in memory with name: catboost_optimization\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting catboost optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-08 12:51:57,581]\u001b[0m Trial 0 finished with value: 0.606567517154166 and parameters: {'num_trees': 437, 'learning_rate': 0.09556428757689246, 'bagging_temperature': 18.567854603473723, 'random_strength': 6.387926357773329, 'depth': 2, 'colsample_bylevel': 0.20919616423534187, 'l2_leaf_reg': 0.5808361216819946}. Best is trial 0 with value: 0.606567517154166.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 12:53:19,079]\u001b[0m Trial 1 finished with value: 0.5476696740373589 and parameters: {'num_trees': 880, 'learning_rate': 0.0641003510568888, 'bagging_temperature': 17.993741867105093, 'random_strength': 1.185260448662222, 'depth': 8, 'colsample_bylevel': 0.6827098485602953, 'l2_leaf_reg': 2.1233911067827616}. Best is trial 1 with value: 0.5476696740373589.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 12:53:26,621]\u001b[0m Trial 2 finished with value: 0.6107493754755131 and parameters: {'num_trees': 263, 'learning_rate': 0.026506405886809047, 'bagging_temperature': 8.301813831028905, 'random_strength': 5.72280788469014, 'depth': 4, 'colsample_bylevel': 0.30386039813862936, 'l2_leaf_reg': 6.118528947223795}. Best is trial 1 with value: 0.5476696740373589.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 12:53:37,817]\u001b[0m Trial 3 finished with value: 0.5793196963776324 and parameters: {'num_trees': 225, 'learning_rate': 0.03629301836816964, 'bagging_temperature': 9.7926842390486, 'random_strength': 5.104629857953324, 'depth': 7, 'colsample_bylevel': 0.23977164751085184, 'l2_leaf_reg': 5.142344384136116}. Best is trial 1 with value: 0.5476696740373589.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 12:53:48,169]\u001b[0m Trial 4 finished with value: 0.7060884933830252 and parameters: {'num_trees': 633, 'learning_rate': 0.014180537144799797, 'bagging_temperature': 15.58107644563452, 'random_strength': 2.5347171131856236, 'depth': 1, 'colsample_bylevel': 0.7642198760773333, 'l2_leaf_reg': 9.656320330745594}. Best is trial 1 with value: 0.5476696740373589.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 12:54:09,678]\u001b[0m Trial 5 finished with value: 0.5543417191568069 and parameters: {'num_trees': 828, 'learning_rate': 0.037415239225603365, 'bagging_temperature': 3.344130736153213, 'random_strength': 7.158097238609412, 'depth': 4, 'colsample_bylevel': 0.1854267643913452, 'l2_leaf_reg': 4.951769101112702}. Best is trial 1 with value: 0.5476696740373589.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 12:54:13,120]\u001b[0m Trial 6 finished with value: 0.6091555620108068 and parameters: {'num_trees': 130, 'learning_rate': 0.09183883618709039, 'bagging_temperature': 7.210719558400406, 'random_strength': 6.962700559185838, 'depth': 3, 'colsample_bylevel': 0.46404761482446766, 'l2_leaf_reg': 5.4671027934327965}. Best is trial 1 with value: 0.5476696740373589.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 12:54:36,183]\u001b[0m Trial 7 finished with value: 0.5624814925362118 and parameters: {'num_trees': 266, 'learning_rate': 0.09726261649881028, 'bagging_temperature': 19.60318776066675, 'random_strength': 9.455490474077703, 'depth': 8, 'colsample_bylevel': 0.5185299851677596, 'l2_leaf_reg': 9.218742350231167}. Best is trial 1 with value: 0.5476696740373589.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 12:54:41,402]\u001b[0m Trial 8 finished with value: 0.6001301026898709 and parameters: {'num_trees': 179, 'learning_rate': 0.027638457617723072, 'bagging_temperature': 2.0854549338529136, 'random_strength': 3.927972976869379, 'depth': 4, 'colsample_bylevel': 0.28994432224172717, 'l2_leaf_reg': 8.287375091519294}. Best is trial 1 with value: 0.5476696740373589.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 12:54:59,898]\u001b[0m Trial 9 finished with value: 0.5663704718042601 and parameters: {'num_trees': 421, 'learning_rate': 0.03528410587186427, 'bagging_temperature': 14.024705995797962, 'random_strength': 2.2683180247728636, 'depth': 7, 'colsample_bylevel': 0.1521854505758396, 'l2_leaf_reg': 9.868869366005173}. Best is trial 1 with value: 0.5476696740373589.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 12:55:50,407]\u001b[0m Trial 10 finished with value: 0.5519395242615028 and parameters: {'num_trees': 981, 'learning_rate': 0.0689800474550518, 'bagging_temperature': 24.268890658908788, 'random_strength': 1.1616568805333767, 'depth': 6, 'colsample_bylevel': 0.7353653566977627, 'l2_leaf_reg': 0.8088762637384688}. Best is trial 1 with value: 0.5476696740373589.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 12:56:41,258]\u001b[0m Trial 11 finished with value: 0.5543615527802682 and parameters: {'num_trees': 983, 'learning_rate': 0.06641952804159108, 'bagging_temperature': 24.939171394383255, 'random_strength': 1.0787263027174958, 'depth': 6, 'colsample_bylevel': 0.7765875537149904, 'l2_leaf_reg': 0.6827047002751119}. Best is trial 1 with value: 0.5476696740373589.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 12:57:36,756]\u001b[0m Trial 12 finished with value: 0.5518657413466044 and parameters: {'num_trees': 995, 'learning_rate': 0.06646558531743482, 'bagging_temperature': 24.869010094902446, 'random_strength': 1.039116050631211, 'depth': 6, 'colsample_bylevel': 0.6335849514570012, 'l2_leaf_reg': 2.440910982111308}. Best is trial 1 with value: 0.5476696740373589.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 12:58:49,922]\u001b[0m Trial 13 finished with value: 0.5494166595047035 and parameters: {'num_trees': 788, 'learning_rate': 0.056581478871409296, 'bagging_temperature': 20.263403900933405, 'random_strength': 3.292932552634695, 'depth': 8, 'colsample_bylevel': 0.6173861042894404, 'l2_leaf_reg': 2.271390116508786}. Best is trial 1 with value: 0.5476696740373589.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:00:01,512]\u001b[0m Trial 14 finished with value: 0.5516862882833993 and parameters: {'num_trees': 774, 'learning_rate': 0.0520747130508929, 'bagging_temperature': 20.19814120724109, 'random_strength': 3.5199187774327427, 'depth': 8, 'colsample_bylevel': 0.6145723139704273, 'l2_leaf_reg': 2.828716090637556}. Best is trial 1 with value: 0.5476696740373589.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:01:13,269]\u001b[0m Trial 15 finished with value: 0.5468153093865584 and parameters: {'num_trees': 798, 'learning_rate': 0.07880873908361924, 'bagging_temperature': 15.87783713777686, 'random_strength': 2.7568367936056006, 'depth': 8, 'colsample_bylevel': 0.6326695465020673, 'l2_leaf_reg': 2.893853823038997}. Best is trial 15 with value: 0.5468153093865584.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:01:51,651]\u001b[0m Trial 16 finished with value: 0.5503815976114257 and parameters: {'num_trees': 612, 'learning_rate': 0.08132953771700396, 'bagging_temperature': 16.014544090395667, 'random_strength': 4.529793421635871, 'depth': 7, 'colsample_bylevel': 0.5357796900987046, 'l2_leaf_reg': 3.7397770574158455}. Best is trial 15 with value: 0.5468153093865584.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:02:28,320]\u001b[0m Trial 17 finished with value: 0.5545109431196253 and parameters: {'num_trees': 871, 'learning_rate': 0.08165744144452267, 'bagging_temperature': 12.069836020742875, 'random_strength': 2.27425817487116, 'depth': 5, 'colsample_bylevel': 0.6822846020743927, 'l2_leaf_reg': 3.363528481917798}. Best is trial 15 with value: 0.5468153093865584.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:03:19,264]\u001b[0m Trial 18 finished with value: 0.5454813494522334 and parameters: {'num_trees': 680, 'learning_rate': 0.0793444543708174, 'bagging_temperature': 16.854381899883002, 'random_strength': 8.73684887675996, 'depth': 8, 'colsample_bylevel': 0.37213843635047056, 'l2_leaf_reg': 1.662278679615742}. Best is trial 18 with value: 0.5454813494522334.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:03:43,871]\u001b[0m Trial 19 finished with value: 0.5563612436349964 and parameters: {'num_trees': 696, 'learning_rate': 0.08068310399124413, 'bagging_temperature': 11.707481009797505, 'random_strength': 9.54374452602474, 'depth': 5, 'colsample_bylevel': 0.3661279084702776, 'l2_leaf_reg': 1.6405553597722977}. Best is trial 18 with value: 0.5454813494522334.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:04:11,222]\u001b[0m Trial 20 finished with value: 0.5554748490132361 and parameters: {'num_trees': 479, 'learning_rate': 0.07557916850879787, 'bagging_temperature': 22.10820047976887, 'random_strength': 8.162809857042156, 'depth': 7, 'colsample_bylevel': 0.40292192782634406, 'l2_leaf_reg': 4.047128166572012}. Best is trial 18 with value: 0.5454813494522334.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:05:13,864]\u001b[0m Trial 21 finished with value: 0.5492022380498152 and parameters: {'num_trees': 718, 'learning_rate': 0.05536398965996639, 'bagging_temperature': 16.326230465042997, 'random_strength': 8.566860846014798, 'depth': 8, 'colsample_bylevel': 0.5541451542695907, 'l2_leaf_reg': 1.7598630084044629}. Best is trial 18 with value: 0.5454813494522334.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:06:33,202]\u001b[0m Trial 22 finished with value: 0.5467687697086875 and parameters: {'num_trees': 873, 'learning_rate': 0.0884087537297093, 'bagging_temperature': 17.149018284828003, 'random_strength': 2.8376468772435586, 'depth': 8, 'colsample_bylevel': 0.6839040137183011, 'l2_leaf_reg': 1.7064164594369777}. Best is trial 18 with value: 0.5454813494522334.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:07:08,181]\u001b[0m Trial 23 finished with value: 0.5493288782807543 and parameters: {'num_trees': 566, 'learning_rate': 0.0896690470182113, 'bagging_temperature': 13.958590280389767, 'random_strength': 4.493159551237775, 'depth': 7, 'colsample_bylevel': 0.49812659769473366, 'l2_leaf_reg': 0.1162096162755315}. Best is trial 18 with value: 0.5454813494522334.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:07:36,881]\u001b[0m Trial 24 finished with value: 0.5424565715832237 and parameters: {'num_trees': 894, 'learning_rate': 0.08821174517774216, 'bagging_temperature': 17.43067578984885, 'random_strength': 2.8416400112792437, 'depth': 6, 'colsample_bylevel': 0.10209975233566276, 'l2_leaf_reg': 1.3847141764572692}. Best is trial 24 with value: 0.5424565715832237.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:08:17,116]\u001b[0m Trial 25 finished with value: 0.5460934136717408 and parameters: {'num_trees': 910, 'learning_rate': 0.08612941026028921, 'bagging_temperature': 22.087048157992804, 'random_strength': 5.455173926891812, 'depth': 6, 'colsample_bylevel': 0.3938294881150971, 'l2_leaf_reg': 0.9608653618021921}. Best is trial 24 with value: 0.5424565715832237.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:08:43,563]\u001b[0m Trial 26 finished with value: 0.5482245815921776 and parameters: {'num_trees': 914, 'learning_rate': 0.09891081159108116, 'bagging_temperature': 23.15727283217432, 'random_strength': 8.080220077228061, 'depth': 5, 'colsample_bylevel': 0.1201160530219364, 'l2_leaf_reg': 1.1087025799114971}. Best is trial 24 with value: 0.5424565715832237.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:09:14,023]\u001b[0m Trial 27 finished with value: 0.553056290794876 and parameters: {'num_trees': 701, 'learning_rate': 0.07303182423208467, 'bagging_temperature': 21.798032186263377, 'random_strength': 5.723180440955267, 'depth': 6, 'colsample_bylevel': 0.358366421695218, 'l2_leaf_reg': 7.065410466488584}. Best is trial 24 with value: 0.5424565715832237.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:09:54,787]\u001b[0m Trial 28 finished with value: 0.5470971958205996 and parameters: {'num_trees': 913, 'learning_rate': 0.08595603834999177, 'bagging_temperature': 21.265923722343185, 'random_strength': 6.495915038471636, 'depth': 6, 'colsample_bylevel': 0.4124393399755026, 'l2_leaf_reg': 0.1492539158948819}. Best is trial 24 with value: 0.5424565715832237.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:10:09,911]\u001b[0m Trial 29 finished with value: 0.562299249609237 and parameters: {'num_trees': 451, 'learning_rate': 0.09336918350193658, 'bagging_temperature': 19.203424653432396, 'random_strength': 7.511419271783517, 'depth': 5, 'colsample_bylevel': 0.2488651214906113, 'l2_leaf_reg': 1.0748056784393323}. Best is trial 24 with value: 0.5424565715832237.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:10:17,650]\u001b[0m Trial 30 finished with value: 0.619595696918811 and parameters: {'num_trees': 363, 'learning_rate': 0.04621600580058591, 'bagging_temperature': 18.14060192874794, 'random_strength': 5.193461925102209, 'depth': 3, 'colsample_bylevel': 0.10018347861329907, 'l2_leaf_reg': 4.328510812991891}. Best is trial 24 with value: 0.5424565715832237.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:11:11,027]\u001b[0m Trial 31 finished with value: 0.5438517170772634 and parameters: {'num_trees': 907, 'learning_rate': 0.08665065457772583, 'bagging_temperature': 17.597413685133645, 'random_strength': 4.1714545722412115, 'depth': 7, 'colsample_bylevel': 0.44448243062337733, 'l2_leaf_reg': 1.485211795169997}. Best is trial 24 with value: 0.5424565715832237.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:11:54,279]\u001b[0m Trial 32 finished with value: 0.546708903338252 and parameters: {'num_trees': 742, 'learning_rate': 0.08398805610306447, 'bagging_temperature': 17.933412415106307, 'random_strength': 4.505044882034468, 'depth': 7, 'colsample_bylevel': 0.4485379885827986, 'l2_leaf_reg': 1.3651774403327914}. Best is trial 24 with value: 0.5424565715832237.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:12:33,469]\u001b[0m Trial 33 finished with value: 0.5456723666172769 and parameters: {'num_trees': 918, 'learning_rate': 0.07291083118706522, 'bagging_temperature': 14.636295258751044, 'random_strength': 3.7760871506427565, 'depth': 6, 'colsample_bylevel': 0.32493037681821246, 'l2_leaf_reg': 0.10841827365986079}. Best is trial 24 with value: 0.5424565715832237.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:13:17,019]\u001b[0m Trial 34 finished with value: 0.5420842050902477 and parameters: {'num_trees': 842, 'learning_rate': 0.07344290290006429, 'bagging_temperature': 14.153840753234743, 'random_strength': 3.978551979203507, 'depth': 7, 'colsample_bylevel': 0.2958844206019531, 'l2_leaf_reg': 0.1970570032216355}. Best is trial 34 with value: 0.5420842050902477.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:13:49,990]\u001b[0m Trial 35 finished with value: 0.5439935699949411 and parameters: {'num_trees': 655, 'learning_rate': 0.07578554319058094, 'bagging_temperature': 12.318224248938057, 'random_strength': 1.9069218206691545, 'depth': 7, 'colsample_bylevel': 0.2672322943774374, 'l2_leaf_reg': 2.885475501655721}. Best is trial 34 with value: 0.5420842050902477.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:14:29,092]\u001b[0m Trial 36 finished with value: 0.5379339618434 and parameters: {'num_trees': 821, 'learning_rate': 0.0712253436783177, 'bagging_temperature': 10.606039174899044, 'random_strength': 1.6568598293187486, 'depth': 7, 'colsample_bylevel': 0.21167463621779836, 'l2_leaf_reg': 2.61044357894621}. Best is trial 36 with value: 0.5379339618434.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:15:09,011]\u001b[0m Trial 37 finished with value: 0.5400971681631013 and parameters: {'num_trees': 841, 'learning_rate': 0.058867695177019584, 'bagging_temperature': 10.077248559948359, 'random_strength': 1.7058625322087861, 'depth': 7, 'colsample_bylevel': 0.2102757384440636, 'l2_leaf_reg': 2.388894249273761}. Best is trial 36 with value: 0.5379339618434.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:15:21,154]\u001b[0m Trial 38 finished with value: 0.6274903549794815 and parameters: {'num_trees': 845, 'learning_rate': 0.0592674876843096, 'bagging_temperature': 9.829800451459915, 'random_strength': 1.6820342231833625, 'depth': 1, 'colsample_bylevel': 0.20919723283169625, 'l2_leaf_reg': 3.3594492043641373}. Best is trial 36 with value: 0.5379339618434.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:15:58,570]\u001b[0m Trial 39 finished with value: 0.5374969328912741 and parameters: {'num_trees': 819, 'learning_rate': 0.06019464042045145, 'bagging_temperature': 6.806898610613213, 'random_strength': 1.7366363198887151, 'depth': 7, 'colsample_bylevel': 0.18625187432587684, 'l2_leaf_reg': 4.544830851147542}. Best is trial 39 with value: 0.5374969328912741.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:16:13,327]\u001b[0m Trial 40 finished with value: 0.5849487165398545 and parameters: {'num_trees': 818, 'learning_rate': 0.0608348114386111, 'bagging_temperature': 5.492096277411969, 'random_strength': 1.8010881765889326, 'depth': 2, 'colsample_bylevel': 0.20542268721168158, 'l2_leaf_reg': 6.059528592302033}. Best is trial 39 with value: 0.5374969328912741.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:16:46,924]\u001b[0m Trial 41 finished with value: 0.5447821775393235 and parameters: {'num_trees': 750, 'learning_rate': 0.04786646101752397, 'bagging_temperature': 10.437165882854812, 'random_strength': 3.0537561093397714, 'depth': 7, 'colsample_bylevel': 0.1722608615686823, 'l2_leaf_reg': 4.496672543608518}. Best is trial 39 with value: 0.5374969328912741.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:17:23,242]\u001b[0m Trial 42 finished with value: 0.5367604798867531 and parameters: {'num_trees': 840, 'learning_rate': 0.06256037597454668, 'bagging_temperature': 8.154227044861916, 'random_strength': 1.5236621528399075, 'depth': 7, 'colsample_bylevel': 0.14725333328138926, 'l2_leaf_reg': 2.2406819443599404}. Best is trial 42 with value: 0.5367604798867531.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:18:02,849]\u001b[0m Trial 43 finished with value: 0.5374495618374759 and parameters: {'num_trees': 826, 'learning_rate': 0.06251347050923288, 'bagging_temperature': 7.5884113400457025, 'random_strength': 1.575112445447142, 'depth': 7, 'colsample_bylevel': 0.22335124943084972, 'l2_leaf_reg': 5.000227584822804}. Best is trial 42 with value: 0.5367604798867531.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:18:43,534]\u001b[0m Trial 44 finished with value: 0.5341385514235721 and parameters: {'num_trees': 947, 'learning_rate': 0.06304236802984786, 'bagging_temperature': 7.498494577297522, 'random_strength': 1.5629210644771856, 'depth': 7, 'colsample_bylevel': 0.14759954838433723, 'l2_leaf_reg': 5.4493059367296866}. Best is trial 44 with value: 0.5341385514235721.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:19:34,119]\u001b[0m Trial 45 finished with value: 0.5321122829920709 and parameters: {'num_trees': 941, 'learning_rate': 0.06322249292804268, 'bagging_temperature': 7.627340260426718, 'random_strength': 1.4206165182365895, 'depth': 8, 'colsample_bylevel': 0.14219546685280987, 'l2_leaf_reg': 5.619823342663956}. Best is trial 45 with value: 0.5321122829920709.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:20:26,500]\u001b[0m Trial 46 finished with value: 0.531972468812868 and parameters: {'num_trees': 960, 'learning_rate': 0.06306816049219394, 'bagging_temperature': 7.620393864058849, 'random_strength': 2.3636434697569837, 'depth': 8, 'colsample_bylevel': 0.15036936592360897, 'l2_leaf_reg': 5.70249606817042}. Best is trial 46 with value: 0.531972468812868.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:21:20,155]\u001b[0m Trial 47 finished with value: 0.5313544467838509 and parameters: {'num_trees': 994, 'learning_rate': 0.06400543326175914, 'bagging_temperature': 8.39455502733986, 'random_strength': 2.4119033873102236, 'depth': 8, 'colsample_bylevel': 0.1470064736145258, 'l2_leaf_reg': 5.5761673094998665}. Best is trial 47 with value: 0.5313544467838509.\u001b[0m\n",
      "\u001b[32m[I 2023-01-08 13:22:16,419]\u001b[0m Trial 48 finished with value: 0.5303909419153083 and parameters: {'num_trees': 955, 'learning_rate': 0.04970656059425884, 'bagging_temperature': 4.605862369391987, 'random_strength': 2.1610845898091626, 'depth': 8, 'colsample_bylevel': 0.17170220706427092, 'l2_leaf_reg': 6.345347577047418}. Best is trial 48 with value: 0.5303909419153083.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if cfg.optim:\n",
    "\n",
    "    # create study\n",
    "    sampler = optuna.samplers.TPESampler(seed=cfg.seed)\n",
    "    max_trials = 2 if cfg.debug else 50\n",
    "    time_limit = 3600 * 0.5\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        sampler=sampler,\n",
    "        study_name= f'{cfg.modelname}_optimization',\n",
    "        direction='minimize')\n",
    "\n",
    "    # perform optimization\n",
    "    print(f'Starting {cfg.modelname} optimization...')\n",
    "    study.optimize(\n",
    "        objective,\n",
    "        n_trials = max_trials,\n",
    "        timeout = time_limit,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 49\n",
      "Best score: 0.5303909419153083\n",
      "Best trial parameters:\n",
      "\tloss_function: RMSE\n",
      "\tcustom_metric: RMSE\n",
      "\ttask_type: CPU\n",
      "\tbootstrap_type: Bayesian\n",
      "\tallow_writing_files: False\n",
      "\tnum_trees: 955\n",
      "\tlearning_rate: 0.04970656059425884\n",
      "\tbagging_temperature: 4.605862369391987\n",
      "\trandom_strength: 2.1610845898091626\n",
      "\tdepth: 8\n",
      "\tcolsample_bylevel: 0.17170220706427092\n",
      "\tl2_leaf_reg: 6.345347577047418\n"
     ]
    }
   ],
   "source": [
    "if cfg.optim:\n",
    "    \n",
    "    # optimization results\n",
    "    print(f\"Number of finished trials: {len(study.trials)}\")\n",
    "    print(f\"Best score: {study.best_value}\")\n",
    "    best_params = {**fixed_params, **study.best_trial.params}\n",
    "    print(\"Best trial parameters:\")\n",
    "    for k, v in best_params.items():\n",
    "        print(f\"\\t{k}: {v}\")\n",
    "\n",
    "    # save best params\n",
    "    best_params_path = f'{params_path}{cfg.modelname}.joblib'\n",
    "    with open(best_params_path, \"wb\") as file:\n",
    "        joblib.dump(best_params, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final parameters:\n",
      "\tloss_function: RMSE\n",
      "\tcustom_metric: RMSE\n",
      "\ttask_type: CPU\n",
      "\tbootstrap_type: Bayesian\n",
      "\tallow_writing_files: False\n",
      "\tnum_trees: 955\n",
      "\tlearning_rate: 0.02\n",
      "\tbagging_temperature: 4.605862369391987\n",
      "\trandom_strength: 2.1610845898091626\n",
      "\tdepth: 8\n",
      "\tcolsample_bylevel: 0.17170220706427092\n",
      "\tl2_leaf_reg: 6.345347577047418\n"
     ]
    }
   ],
   "source": [
    "# load best params\n",
    "best_params_path = f'{params_path}{cfg.modelname}.joblib'\n",
    "with open(best_params_path, 'rb') as file:\n",
    "    best_params = joblib.load(file)\n",
    "\n",
    "best_params['learning_rate'] = 0.02\n",
    "print(\"Final parameters:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"\\t{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv training and predict\n",
    "def train_model(train, test, params):\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(30*'*', f'Model: {cfg.modelname}', 30*'*', '\\n')\n",
    "\n",
    "    # get data\n",
    "    x = train[FEATURES]\n",
    "    y = train[TARGET]\n",
    "    xtest = test[FEATURES]\n",
    "\n",
    "    # cv loop\n",
    "    cv = KFold(n_splits=cfg.nfolds, shuffle=True, random_state=cfg.seed)\n",
    "    preds, cv_scores = [], []\n",
    "    for fold, (train_idx, test_idx) in enumerate(cv.split(x, y)):\n",
    "\n",
    "        print(f'fold {fold+1}/{cfg.nfolds}...')\n",
    "        fold_start_time = time.time()\n",
    "\n",
    "        # split data\n",
    "        x_train, x_val = x.iloc[train_idx], x.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        # define and fit model\n",
    "        model = catboost.CatBoostRegressor(**params)\n",
    "        model.fit(\n",
    "            catboost.Pool(x_train, y_train),\n",
    "            eval_set=catboost.Pool(x_val, y_val),\n",
    "            early_stopping_rounds=20,\n",
    "            verbose=200\n",
    "        )\n",
    "\n",
    "        # validation score\n",
    "        cv_score = np.sqrt(mean_squared_error(y_val, model.predict(x_val)))\n",
    "        cv_scores.append(cv_score)\n",
    "\n",
    "        # predict test data\n",
    "        preds.append(model.predict(xtest))\n",
    "\n",
    "        fold_run_time = time.time() - fold_start_time\n",
    "        print(f'rmse: {cv_score:.4f}, run time: {fold_run_time:.2f}\\n')\n",
    "\n",
    "    # print results\n",
    "    run_time = time.time() - start_time\n",
    "    print(f'\\nTraining completed. Total run time: {run_time:2f}')\n",
    "    print(f'CV score:\\n\\t mean: {np.mean(cv_scores):0.6f}\\n\\t std: {np.std(cv_scores):0.6f}')\n",
    "\n",
    "    return (cv_scores, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** Model: catboost ****************************** \n",
      "\n",
      "fold 1/5...\n",
      "0:\tlearn: 1.1446988\ttest: 1.1394422\tbest: 1.1394422 (0)\ttotal: 11.5ms\tremaining: 11s\n",
      "200:\tlearn: 0.5793968\ttest: 0.5701809\tbest: 0.5701809 (200)\ttotal: 2.29s\tremaining: 8.58s\n",
      "400:\tlearn: 0.5512678\ttest: 0.5457476\tbest: 0.5457476 (400)\ttotal: 4.52s\tremaining: 6.24s\n",
      "600:\tlearn: 0.5385791\ttest: 0.5369017\tbest: 0.5369017 (600)\ttotal: 6.72s\tremaining: 3.96s\n",
      "800:\tlearn: 0.5293133\ttest: 0.5315741\tbest: 0.5315741 (800)\ttotal: 8.94s\tremaining: 1.72s\n",
      "954:\tlearn: 0.5233545\ttest: 0.5282434\tbest: 0.5282434 (954)\ttotal: 10.6s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5282434092\n",
      "bestIteration = 954\n",
      "\n",
      "rmse: 0.5282, run time: 10.79\n",
      "\n",
      "fold 2/5...\n",
      "0:\tlearn: 1.1446188\ttest: 1.1356876\tbest: 1.1356876 (0)\ttotal: 11.8ms\tremaining: 11.2s\n",
      "200:\tlearn: 0.5775014\ttest: 0.5834148\tbest: 0.5834148 (200)\ttotal: 2.21s\tremaining: 8.28s\n",
      "400:\tlearn: 0.5490621\ttest: 0.5617387\tbest: 0.5617387 (400)\ttotal: 4.41s\tremaining: 6.09s\n",
      "600:\tlearn: 0.5359569\ttest: 0.5533811\tbest: 0.5533811 (600)\ttotal: 6.61s\tremaining: 3.9s\n",
      "800:\tlearn: 0.5264138\ttest: 0.5482325\tbest: 0.5482325 (800)\ttotal: 9.19s\tremaining: 1.77s\n",
      "954:\tlearn: 0.5203704\ttest: 0.5452917\tbest: 0.5452917 (954)\ttotal: 11.2s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5452916854\n",
      "bestIteration = 954\n",
      "\n",
      "rmse: 0.5453, run time: 11.36\n",
      "\n",
      "fold 3/5...\n",
      "0:\tlearn: 1.1422294\ttest: 1.1513717\tbest: 1.1513717 (0)\ttotal: 11.8ms\tremaining: 11.2s\n",
      "200:\tlearn: 0.5769612\ttest: 0.5813279\tbest: 0.5813279 (200)\ttotal: 2.34s\tremaining: 8.76s\n",
      "400:\tlearn: 0.5497705\ttest: 0.5572868\tbest: 0.5572868 (400)\ttotal: 4.58s\tremaining: 6.32s\n",
      "600:\tlearn: 0.5372829\ttest: 0.5486275\tbest: 0.5486275 (600)\ttotal: 6.77s\tremaining: 3.99s\n",
      "800:\tlearn: 0.5278023\ttest: 0.5428112\tbest: 0.5428112 (800)\ttotal: 8.96s\tremaining: 1.72s\n",
      "954:\tlearn: 0.5217413\ttest: 0.5394451\tbest: 0.5394451 (954)\ttotal: 10.6s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5394451097\n",
      "bestIteration = 954\n",
      "\n",
      "rmse: 0.5394, run time: 10.83\n",
      "\n",
      "fold 4/5...\n",
      "0:\tlearn: 1.1409567\ttest: 1.1523338\tbest: 1.1523338 (0)\ttotal: 10.7ms\tremaining: 10.2s\n",
      "200:\tlearn: 0.5738939\ttest: 0.5993349\tbest: 0.5993349 (200)\ttotal: 2.24s\tremaining: 8.39s\n",
      "400:\tlearn: 0.5459944\ttest: 0.5762495\tbest: 0.5762495 (400)\ttotal: 4.44s\tremaining: 6.14s\n",
      "600:\tlearn: 0.5328086\ttest: 0.5669041\tbest: 0.5669041 (600)\ttotal: 6.64s\tremaining: 3.91s\n",
      "800:\tlearn: 0.5236520\ttest: 0.5617507\tbest: 0.5617507 (800)\ttotal: 8.87s\tremaining: 1.7s\n",
      "954:\tlearn: 0.5172775\ttest: 0.5581048\tbest: 0.5581048 (954)\ttotal: 10.5s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5581048386\n",
      "bestIteration = 954\n",
      "\n",
      "rmse: 0.5581, run time: 10.71\n",
      "\n",
      "fold 5/5...\n",
      "0:\tlearn: 1.1451074\ttest: 1.1385858\tbest: 1.1385858 (0)\ttotal: 11.9ms\tremaining: 11.4s\n",
      "200:\tlearn: 0.5764010\ttest: 0.5796528\tbest: 0.5796527 (199)\ttotal: 2.24s\tremaining: 8.39s\n",
      "400:\tlearn: 0.5485774\ttest: 0.5575769\tbest: 0.5575769 (400)\ttotal: 4.46s\tremaining: 6.16s\n",
      "600:\tlearn: 0.5359233\ttest: 0.5496081\tbest: 0.5496081 (600)\ttotal: 6.65s\tremaining: 3.92s\n",
      "800:\tlearn: 0.5271148\ttest: 0.5448111\tbest: 0.5448111 (800)\ttotal: 8.87s\tremaining: 1.71s\n",
      "954:\tlearn: 0.5211536\ttest: 0.5418267\tbest: 0.5418267 (954)\ttotal: 10.5s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5418267166\n",
      "bestIteration = 954\n",
      "\n",
      "rmse: 0.5418, run time: 10.72\n",
      "\n",
      "\n",
      "Training completed. Total run time: 54.437438\n",
      "CV score:\n",
      "\t mean: 0.542582\n",
      "\t std: 0.009636\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "scores, preds = train_model(train, test, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cv score and final predictions\n",
    "score = np.mean(scores)\n",
    "final_preds = np.mean(np.array(preds), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions\n",
    "sub = pd.read_csv('../data/raw/sample_submission.csv', index_col=0)\n",
    "sub[TARGET] = final_preds\n",
    "sub.head()\n",
    "\n",
    "out_path = '../submissions/'\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "sub.to_csv(out_path + f'{cfg.modelname}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b94cdfffcc6f6f3237d201e414566911455475e8fe8860b009b063936548ab37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
