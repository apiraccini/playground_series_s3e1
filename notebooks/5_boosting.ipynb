{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform; print(platform.platform())\n",
    "import sys; print(\"Python\", sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import optuna\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cfg:\n",
    "    modelname = 'lgb'\n",
    "    debut = True\n",
    "    optim = True\n",
    "    seed = 42\n",
    "    nfolds = 5\n",
    "    njobs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_csv('../data/final/train.csv')\n",
    "test = pd.read_csv('../data/final/test.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick info\n",
    "TARGET = 'MedHouseVal'\n",
    "FEATURES = [c for c in train.columns if c not in [TARGET]]\n",
    "\n",
    "print(f'Target: {TARGET}\\nFeatures: {FEATURES}')\n",
    "print('Train set shape:', train.shape)\n",
    "print('Test set shape:', test.shape)\n",
    "\n",
    "x = train[FEATURES]\n",
    "y = train[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "studies_path = '../src/training_files/studies/'\n",
    "cv = KFold(n_splits=cfg.nfolds, shuffle=True, random_state=cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed params\n",
    "fixed_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'device': cfg.device,\n",
    "        'verbosity': -1,\n",
    "        'early_stopping_round': 15,\n",
    "    }\n",
    "\n",
    "# objective function for optimization\n",
    "def objective(trial):\n",
    "    \n",
    "    # trial parameters\n",
    "    tuning_params = {\n",
    "        'n_estimators' : trial.suggest_int('n_estimators', 100, 3000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 512),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1.0),\n",
    "        'subsample_freq': trial.suggest_int('subsample_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "    }\n",
    "\n",
    "    params = {**fixed_params, **tuning_params}\n",
    "\n",
    "    # train and score with cv\n",
    "    scores = []\n",
    "    for train_index, test_index in cv.split(x, y):\n",
    "        \n",
    "        train_x, valid_x = x.iloc[train_index], x.iloc[test_index]\n",
    "        train_y, valid_y = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(\n",
    "            train_x,\n",
    "            train_y,\n",
    "            eval_set=[(valid_x, valid_y)],\n",
    "            callbacks=[lgb.log_evaluation(period=0, show_stdv=False)]\n",
    "        )\n",
    "        \n",
    "        acc = np.sqrt(mean_squared_error(valid_y,(model.predict(valid_x))))\n",
    "        scores.append(acc)\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.optim:\n",
    "\n",
    "    # create study\n",
    "    sampler = optuna.samplers.TPESampler(seed=cfg.seed)\n",
    "    max_trials = 2 if cfg.debug else 50\n",
    "    time_limit = 3600 * 0.5\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        sampler=sampler,\n",
    "        study_name= f'{cfg.modelname}_optimization',\n",
    "        direction='maximize')\n",
    "\n",
    "    # perform optimization\n",
    "    print(f'Starting {cfg.modelname} optimization...')\n",
    "    study.optimize(\n",
    "        objective,\n",
    "        n_trials = max_trials,\n",
    "        timeout = time_limit,\n",
    "    )\n",
    "\n",
    "    # optimization results\n",
    "    print(f\"\\nNumber of finished trials: {len(study.trials)}\")\n",
    "    print(f\"Best score: {study.best_value}\")\n",
    "    best_params = {**fixed_params, **study.best_trial.params}\n",
    "    print(\"Best trial parameters:\")\n",
    "    for k, v in best_params.items():\n",
    "        print(f\"\\t{k}: {v}\")\n",
    "\n",
    "    # save best params\n",
    "    params_path = f'{studies_path}{cfg.modelname}_bestparams.joblib'\n",
    "    with open(params_path, \"wb\") as file:\n",
    "        joblib.dump(best_params, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
